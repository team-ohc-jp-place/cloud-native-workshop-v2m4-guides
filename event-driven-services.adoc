= Lab2 - イベント駆動/リアクティブサービス
:experimental:

従来のマイクロサービスアーキテクチャは、通常、異なる機能を持つ多くの個別のサービスで構成されています。各アプリケーションサービスは、データを取得するためにサービスと通信する必要がある多くのクライアントを持っています。エンドユーザーのクリック、RESTful API、データを生成するIoTデバイスなど、すべてがデータのストリームになり得るため、データストリームを扱うのはより複雑になります。そして、これらのサービスがハイブリッドまたはマルチクラウドのインフラストラクチャ上で実行されている場合、複雑さは上昇します。

イベント駆動型アーキテクチャでは、リアクティブ・プログラミングと分散メッセージングを使用して、データ・ストリームをイベントとして扱うことができます。*リアクティブ・プログラミング* は、データ・ストリームと変化の伝播に関係する非同期プログラミング・パラダイムです。前のラボでは、インベントリ、カタログ、ショッピングカート、注文サービスを明らかな相互作用を持って開発しました。

このラボでは、ショッピングカートと注文の実装を変更し、Cloud Native アプリケーションアーキテクチャのイベント駆動/リアクティブアプリケーションとして決済サービスを追加します。これらの Cloud Native アプリケーションは、メッセージング/ストリーミングのバックボーンとして AMQ Streams (Apache Kafka ベース) を使用します。AMQ Streams を使用すると、OpenShift 上で Apache Kafka を簡単に実行できるようになります :

* 水平方向のスケーラビリティを考慮した設計
* パーティションレベルでのメッセージ順序保証
* メッセージの巻き戻し/再生 - _Long term_ ストレージは、メッセージを再生してアプリケーションの状態を再構築することを可能にします。

=== このラボのゴール

目標は、*Red Hat Runtimes* 上で高度なクラウドネイティブアプリケーションを開発し、分散メッシング機能のための *AMQ Streams* を含む *OpenShift 4* 上にデプロイすることです。このラボの後には、次のようなものを完成させる必要があります :

image::lab2-goal.png[goal, 700]

スケーラビリティは Apache Kafka の主要な機能の一つである。これはデータを分割し、複数のブローカーに分散させることで実現されます。このようなデータシャーディングは、クライアントがどのようにブローカーに接続して使用するかにも大きな影響を与えます。これは、Kafka が Kubernetes のようなプラットフォーム内で実行されているが、そのプラットフォームの外部からアクセスされている場合に特に顕著である。

https://strimzi.io/[Strimzi] は、 https://developers.redhat.com/videos/youtube/CZhOJ_ysIiI/[Apache kafka] を実行するためのコンテナイメージと演算子を提供するオープンソースプロジェクトです。

このラボでは、 https://www.redhat.com/en/technologies/jboss-middleware/amq?extIdCarryOver=true&sc_cid=701f2000001OH7TAAW[Red Hat AMQ^] を通じて Strimzi と Apache Kafka プロジェクトの製品化されサポートされたバージョンを使用します。

=== 1. Kafka クラスターとトピックの生成

AMQ Streams は以下の _Operators_ を使って既にインストールされているので、このラボではインストールする必要はありません :

* *Kafka Operator* - OpenShift クラスタ内の Apache Kafka クラスタのデプロイと管理を担当。
* *Topic Operator* - OpenShift クラスタ内で稼働する Kafka クラスタ内の Kafka トピックの管理を担当。
* *User Operator* - OpenShift クラスタ内で稼働する Kafka クラスタ内の Kafka ユーザの管理を担当。

AMQ におけるオペレーターの基本的なアーキテクチャは以下の通りです :

image::kafka-operators-arch.png[amqstreams, 700]

** Kafka クラスタ**を作成してみましょう。左側のプロジェクト概要の _From Catalog_ ボックスにある *+Add* をクリックします :

image::kafka-catalog.png[kafka, 700]

検索ボックスに `kafka` と入力して、*Kafka* をクリックします :

image::kafka-create.png[kafka, 700]

*Create* をクリックすると、YAML エディタで *Kafka* クラスタを定義します。全ての値をそのままにして、下部の *Create* をクリックしてください :

image::kafka-create-detail.png[kafka, 700]

次に、Kafka _Topic_ を作成します。もう一度、_Add > From Catalog_ をクリックし、検索ボックスに `kafka topic` と入力して、*Kafka Topic* をクリックします :

image::kafka-topic-catalog.png[kafka, 700]

*Create* をクリックすると、YAML エディタで *KafkaTopic* オブジェクトを定義します。名前を `orders` に変更して、下部の *Create* をクリックしてください :

image::kafka-topic-orders-create.png[kafka, 700]

上記と同じプロセスを使用して別のトピックを作成しますが、名前は `payments` です :

image::kafka-topic-catalog.png[kafka, 700]

名前を `payments` に変更して、下部の *Create* をクリックします。

image::kafka-topic-payments-create.png[kafka, 700]

*よくできました。* これで、Kafka クラスタが `payments` と `orders` という 2 つの Kafka トピックで動作していることになります。

image::kafka-topics-created.png[kafka, 700]

=== 2. 決済サービスの開発とデプロイ

私たちの _Payment Service_ は、ショッピングカートで注文がチェックアウトされた際に、クレジットカードや銀行ベースの支払いを含む様々な支払い方法で電子的な支払いを受け入れるためのオンラインサービスを提供します。実際には何もしませんが、オンラインショッピングの注文が当社のサービスに投稿されたときに*処理する支払いマイクロサービスを表しています。

CodeReady Workspaces で、*payment-service* ディレクトリを展開します。

image::codeready-workspace-payment-project.png[catalog, 700]

このステップでは、Quarkus ベースの決済サービスが Kafka を使用して注文イベントを受信し、決済イベントに _反応_ する方法を学びます。

CodeReady Workspaces Terminal で Quarkus Kafka の拡張機能を使って Maven の依存関係を追加してみましょう :

[source,sh,role="copypaste"]
----
mvn -q quarkus:add-extension -Dextensions="messaging-kafka" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/payment-service
----

アウトプットに以下を確認することができます :

[source,console]
----
✅ Extension io.quarkus:quarkus-smallrye-reactive-messaging-kafka has been installed
----

このコマンドは、Quarkus アプリケーション用の Kafka 拡張機能をインポートし、Kafka クラスタと統合するために必要なすべての機能を提供します。これを `pom.xml` に追加します。:

[source,xml]
----
    ...
    <dependency>
      <groupId>io.quarkus</groupId>
      <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>
    </dependency>
    ...
----

まず、*@ConfigProperty* とメッセージを送信するための *Producer* フィールドを使って設定を注入することから始めましょう。また、後でデバッグメッセージを見ることができるように `log` フィールドを追加します。

このコードを `PaymentResource.java` ファイル (`src/main/java/com/redhat/cloudnative` ディレクトリ) の `// TODO: Add Messaging ConfigProperty here` マーカーに追加します :

[source,java,role="copypaste"]
----
    @ConfigProperty(name = "mp.messaging.outgoing.payments.bootstrap.servers")
    public String bootstrapServers;

    @ConfigProperty(name = "mp.messaging.outgoing.payments.topic")
    public String paymentsTopic;

    @ConfigProperty(name = "mp.messaging.outgoing.payments.value.serializer")
    public String paymentsTopicValueSerializer;

    @ConfigProperty(name = "mp.messaging.outgoing.payments.key.serializer")
    public String paymentsTopicKeySerializer;

    private Producer<String, String> producer;

    public static final Logger log = LoggerFactory.getLogger(PaymentResource.class);
----

次に、このラボではKafka から直接送られてきますが、後に HTTP POST イベントとして送られてくる受信イベントを処理するためのメソッドが必要です。

`// TODO: Add handleCloudEvent method here` マーカーの箇所に次のコードを追加してください :

[source,java,role="copypaste"]
----
    @POST
    @Consumes(MediaType.APPLICATION_JSON)
    @Produces(MediaType.APPLICATION_JSON)
    public void handleCloudEvent(String cloudEventJson) {
        String orderId = "unknown";
        String paymentId = "" + ((int)(Math.floor(Math.random() * 100000)));

        try {
            log.info("received event: " + cloudEventJson);
            JsonObject event = new JsonObject(cloudEventJson);
            orderId = event.getString("orderId");
            String total = event.getString("total");
            JsonObject ccDetails = event.getJsonObject("creditCard");
            String name = event.getString("name");

            // fake processing time
            Thread.sleep(5000); // <1>
            if (!ccDetails.getString("number").startsWith("4")) {
                fail(orderId, paymentId, "Invalid Credit Card: " + ccDetails.getString("number"));
            } else {
                pass(orderId, paymentId, "Payment of " + total + " succeeded for " + name + " CC details: " + ccDetails.toString());
            }
        } catch (Exception ex) {
             fail(orderId, paymentId, "Unknown error: " + ex.getMessage() + " for payment: " + cloudEventJson);
        }
    }
----
<1> これは、5 秒のクレジットカード処理時間をシミュレートします

ここで、上で参照した `pass()` と `fail()` メソッドを実装する必要があります。これらのメソッドは _producer_ フィールドを使って Kafka にメッセージを送信します。

`// TODO: Add pass method here` マーカーの場所に次のコードを追加してください :

[source,java,role="copypaste"]
----
    private void pass(String orderId, String paymentId, String remarks) {

        JsonObject payload = new JsonObject();
        payload.put("orderId", orderId);
        payload.put("paymentId", paymentId);
        payload.put("remarks", remarks);
        payload.put("status", "COMPLETED");
        log.info("Sending payment success: " + payload.toString());
        producer.send(new ProducerRecord<String, String>(paymentsTopic, payload.toString()));
    }
----

`// TODO: Add fail method here` マーカーの箇所に次のコードを追加してください :

[source,java,role="copypaste"]
----
    private void fail(String orderId, String paymentId, String remarks) {
        JsonObject payload = new JsonObject();
        payload.put("orderId", orderId);
        payload.put("paymentId", paymentId);
        payload.put("remarks", remarks);
        payload.put("status", "FAILED");
        log.info("Sending payment failure: " + payload.toString());
        producer.send(new ProducerRecord<String, String>(paymentsTopic, payload.toString()));
    }
----

次に、Kafka からイベントを受け取るメソッドを追加します。これには MicroProfile のリアクティブメッセージング API `@Incoming` アノテーションを使います。

`// TODO: Add consumer method here` マーカーの箇所に次のコードを追加してください :

[source,java,role="copypaste"]
----
    @Incoming("orders")
    public CompletionStage<Void> onMessage(KafkaRecord<String, String> message)
            throws IOException {

        log.info("Kafka message with value = {} arrived", message.getPayload());
        handleCloudEvent(message.getPayload());
        return message.ack();
    }
----

最後に、Kafka のプロデューサーを初期化するためのメソッドが必要です(コンシューマーは Quarkus Kafka 拡張機能を介して自動的に初期化されます)。Quarkus の `StartupEvent` Lifecycle リスナー API を使用し、`@Observes` アノテーションを付けて、このメソッドをアプリの起動時に実行すべきものとしてマークします :

`// TODO: Add init method here` マーカーの箇所に次のコードを追加してください :

[source,java,role="copypaste"]
----
    public void init(@Observes StartupEvent ev) {
        Properties props = new Properties();

        props.put("bootstrap.servers", bootstrapServers);
        props.put("value.serializer", paymentsTopicValueSerializer);
        props.put("key.serializer", paymentsTopicKeySerializer);
        producer = new KafkaProducer<String, String>(props);
    }
----

このメソッドは `orders` トピックから Kafka ストリームを消費し、`handleCloudEvent()` メソッドを呼び出します。後でこのメソッドを削除して、Knative Events を使用して受信ストリームを処理します。しかし、今のところはこのメソッドを使用してトピックをリッスンします。

Quarkus とその拡張機能は `application.properties` ファイルによって設定されます。このファイルを開きます(`src/main/resources` ディレクトリ)。

`# TODO: Add for messaging configuration` マーカーの箇所にこれらの値を追加してください :

[source,properties,role="copypaste"]
----
# Outgoing stream
mp.messaging.outgoing.payments.bootstrap.servers=my-cluster-kafka-bootstrap:9092
mp.messaging.outgoing.payments.connector=smallrye-kafka
mp.messaging.outgoing.payments.topic=payments
mp.messaging.outgoing.payments.value.serializer=org.apache.kafka.common.serialization.StringSerializer
mp.messaging.outgoing.payments.key.serializer=org.apache.kafka.common.serialization.StringSerializer

# Incoming stream (unneeded when using Knative events)
mp.messaging.incoming.orders.connector=smallrye-kafka
mp.messaging.incoming.orders.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.orders.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.orders.bootstrap.servers=my-cluster-kafka-bootstrap:9092
mp.messaging.incoming.orders.group.id=payment-order-service
mp.messaging.incoming.orders.auto.offset.reset=earliest
mp.messaging.incoming.orders.enable.auto.commit=true
mp.messaging.incoming.orders.request.timeout.ms=30000
----

OpenShift 拡張機能を使用してプロジェクトをビルドしてデプロイし、CodeReady Workspaces Terminal を介してデプロイするために maven プラグインを使用します :

[source,sh,role="copypaste"]
----
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/payment-service
----
出力は `BUILD SUCCESS` で終わるはずです。

実際に展開されていることを確認してください :

[source,sh,role="copypaste"]
----
oc rollout status -w dc/payment
----

続ける前に、そのコマンドが *replication controller _payment-1_ successfully rolled out* を報告するのを待ちます。

そして、アイテムには適切なアイコンでラベルを貼ります :

[source,sh,role="copypaste"]
----
oc label dc/payment app.kubernetes.io/part-of=payment --overwrite && \
oc annotate dc/payment app.openshift.io/connects-to=my-cluster --overwrite && \
oc annotate dc/payment app.openshift.io/vcs-ref=ocp-4.5 --overwrite
----

最後に、実際にロールアウトが完了していることを確認します。オーダーは {{console_url }}/topology/ns/{{user_id }}}-cloudnativeapps[Topology View^] にアクセスしてください。青い丸が表示されていることを確認してください!

image::payment-topology.png[order, 700]

支払いアプリケーションをテストするには、`my-cluster-kafka-0` のポッドをクリックします。:

image::my-cluster-kafka-0.png[payment, 700]

Kafka トピックを CLI 経由で見て、Kafka でメッセージが送受信されていることを確認します。OpenShift の *Terminal* タブをクリックして(CodeReady Workspace ではありません！)、以下のコマンドを実行します :

[source,sh,role="copypaste"]
----
bin/kafka-console-consumer.sh --topic payments --bootstrap-server localhost:9092
----

image::kafka-console-consumer.png[payment, 900]

このタブを開いたままにしておくと、Kafka メッセージのデバッガとして動作します。

さて、*CodeReady Workspaces* に戻って、新しいターミナルを開きます。

`curl`を使って新しいトピックメッセージを作成してみましょう :

まず、新しい決済サービスのURLを取得し、環境変数に格納します :

[source,sh,role="copypaste"]
----
export URL=http://$(oc get route -n {{ USER_ID}}-cloudnativeapps payment -o jsonpath={% raw %}"{.spec.host}"{% endraw %})
----

次に、これを実行して、HTTP POST で決済サービスにメッセージを注文の例と共に送信します :

[source,sh,role="copypaste"]
----
curl -i -H 'Content-Type: application/json' -X POST -d'{"orderId": "12321","total": "232.23", "creditCard": {"number": "4232454678667866","expiration": "04/22","nameOnCard": "Jane G Doe"}, "billingAddress": "123 Anystreet, Pueblo, CO 32213", "name": "Jane Doe"}' $URL
----

これは5秒で戻ってきます(当社の偽クレジットカード処理時間)。

支払いサービスはこの _order_ を受信し、Kafka _payment_ トピックに _payment_ の結果を生成します。`Pod Terminal` では以下のような結果が得られます :

[source,shell]
----
{"orderId":"12321","paymentId":"25658","remarks":"Payment of 232.23 succeeded for Jane Doe CC details: {\"number\":\"4232454678667866\",\"expiration\":\"04/22\",\"nameOnCard\":\"Jane G Doe\"}","status":"COMPLETED"}
----


これは、`order-service` がバックエンドで注文を正常に処理し、支払い処理者に送ることができることを示しています。

次のステップに進む前に、kbd:[CTRL+C] で Kafka コンシューマコンソールを停止します :

image::kafka-console-consumer-stop.png[payment, 900]

=== 3. cart-service に Kafka クライアントを追加

これまでに、小売店のショッピングデータで動作するマイクロサービスをいくつか追加しました。例えば、一度ユーザーがチェックアウトすると、注文サービスや支払いサービスのような他のサービスがこの情報を必要とし、さらに処理をしたいと考えています。そこで、cart-service を Kafka と統合して、買い物客がチェックアウトしたときに注文メッセージを送信できるようにします。

Quarkus *Kafka* 拡張機能を使用して Maven の依存関係を追加します :

[source,sh,role="copypaste"]
----
mvn -q quarkus:add-extension -Dextensions="messaging-kafka" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/cart-service
----

以下の出力を確認できます :

[source,console]
----
✅ Extension io.quarkus:quarkus-smallrye-reactive-messaging-kafka has been installed
----

これにより、cart-service アプリに Kafka 拡張機能と API が追加されます。

支払いサービスと同様に、このコードを `com.redhat.cloudnative` パッケージ内の `CartResource` クラス内の `// TODO: Add annotation of orders messaging configuration here` マーカーに追加します :

[source,java,role="copypaste"]
----
    @ConfigProperty(name = "mp.messaging.outgoing.orders.bootstrap.servers")
    public String bootstrapServers;

    @ConfigProperty(name = "mp.messaging.outgoing.orders.topic")
    public String ordersTopic;

    @ConfigProperty(name = "mp.messaging.outgoing.orders.value.serializer")
    public String ordersTopicValueSerializer;

    @ConfigProperty(name = "mp.messaging.outgoing.orders.key.serializer")
    public String ordersTopicKeySerializer;

    private Producer<String, String> producer;
----

次に、以下の `import` 文の `コメントを解除` します (なければ追加します):

[source,java]
----
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.header.internals.RecordHeaders;
----

`init()` メソッドは Kafka の設定を作成しますが、この設定を外部化してクラスのプロパティとして変数を注入しています。空の `init()` メソッドを以下のコードで置き換えます :

[source,java,role="copypaste"]
----
    public void init(@Observes StartupEvent ev) {
        Properties props = new Properties();

        props.put("bootstrap.servers", bootstrapServers);
        props.put("value.serializer", ordersTopicValueSerializer);
        props.put("key.serializer", ordersTopicKeySerializer);
        producer = new KafkaProducer<String, String>(props);
    }
----

これは、Order POJO をパラメタとして受け取り、それを JSON にシリアライズして Kafka トピックに送信します。空の `sendOrder()` メソッドをこのコードで置き換えます :

[source,java,role="copypaste"]
----
    private void sendOrder(Order order, String cartId) {
        order.setTotal(shoppingCartService.getShoppingCart(cartId).getCartTotal() + "");
        ProducerRecord<String, String> producerRecord = new ProducerRecord<>(ordersTopic, null, null, null, Json.encode(order), new RecordHeaders().add("content-type", "application/json".getBytes()));
        producer.send(producerRecord);
        log.info("Sent message: " + Json.encode(order));
    }
----

それでは、チェックアウト時に `sendOrder()` メソッドに呼び出しを追加してみましょう。`checkout()` のコードを以下のコードに置き換えてください:

[source,java,role="copypaste"]
----
    @POST
    @Path("/checkout/{cartId}")
    @Consumes(MediaType.APPLICATION_JSON)
    @Produces(MediaType.APPLICATION_JSON)
    @Operation(summary = "checkout")
    public ShoppingCart checkout(@PathParam("cartId") String cartId, Order order) {
        sendOrder(order, cartId);
        return shoppingCartService.checkout(cartId);
    }
----

もうすぐです。次に、`# TODO: Add Kafka messaging keys and values here` マーカーの `application.properties` ファイルに設定を追加してみましょう。(`cart-service` プロジェクトの `src/main/resources`) :

[source,none,role="copypaste"]
----
mp.messaging.outgoing.orders.bootstrap.servers=my-cluster-kafka-bootstrap:9092
mp.messaging.outgoing.orders.connector=smallrye-kafka
mp.messaging.outgoing.orders.topic=orders
mp.messaging.outgoing.orders.value.serializer=org.apache.kafka.common.serialization.StringSerializer
mp.messaging.outgoing.orders.key.serializer=org.apache.kafka.common.serialization.StringSerializer
----

以下のコマンドを使用して _cart service_ を再パッケージ化し、CodeReady Workspaces Terminal を介してデプロイするために maven プラグインを使用します :

[source,sh,role="copypaste"]
----
mvn clean package -DskipTests -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/cart-service && \
oc label dc/cart app.kubernetes.io/part-of=cart --overwrite &&  \
oc annotate dc/cart app.openshift.io/connects-to=my-cluster,datagrid-service --overwrite
----

=== 4. order-service へ Kafka クライアントの追加

*payments* サービスと同様に、*order* サービスは注文をリッスンしますが、支払いは処理しません。この機能をオーダーサービスに追加してみましょう。

Quarkus *Kafka* 拡張機能を使用してMavenの依存関係を追加します :

[source,sh,role="copypaste"]
----
mvn -q quarkus:add-extension -Dextensions="messaging-kafka" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/order-service
----

以下のアウトプットを確認できます :

[source,console]
----
✅ Extension io.quarkus:quarkus-smallrye-reactive-messaging-kafka has been installed
----

このコマンドは、Quarkus アプリケーション用の Kafka 拡張機能をインポートして Maven プロジェクトを生成し、Kafka と統合して _payments_ と _orders_ トピックをサブスクライブするために必要なすべての機能を提供します。

Orderサービスにおいて、着信メッセージと発信メッセージを処理するには、`order-service/src/main/java/com/redhat/cloudnative` ディレクトリに `KafkaOrders.java` という名前の新しい Java クラスを作成して、Kafka の _orders_ と _payments_ トピックからのメッセージを利用します。以下のコード全体を _KafkaOrders.java_ にコピーします。

[source,java,role="copypaste"]
----
package com.redhat.cloudnative;

import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.enterprise.context.ApplicationScoped;

import java.io.IOException;
import java.util.concurrent.CompletionStage;

import javax.inject.Inject;
import io.vertx.core.json.JsonObject;

@ApplicationScoped
public class KafkaOrders {

    private static final Logger LOG = LoggerFactory.getLogger(KafkaOrders.class);

    @Inject
    OrderService orderService;

    @Incoming("orders")
    public CompletionStage<Void> onMessage(KafkaRecord<String, String> message)
            throws IOException {

        LOG.info("Kafka order message with value = {} arrived", message.getPayload());

        JsonObject orders = new JsonObject(message.getPayload());
        Order order = new Order();
        order.setOrderId(orders.getString("orderId"));
        order.setName(orders.getString("name"));
        order.setTotal(orders.getString("total"));
        order.setCcNumber(orders.getJsonObject("creditCard").getString("number"));
        order.setCcExp(orders.getJsonObject("creditCard").getString("expiration"));
        order.setBillingAddress(orders.getString("billingAddress"));
        order.setStatus("PROCESSING");
        orderService.add(order);

        return message.ack();
    }

    @Incoming("payments")
    public CompletionStage<Void> onMessagePayments(KafkaRecord<String, String> message)
            throws IOException {

        LOG.info("Kafka payment message with value = {} arrived", message.getPayload());

        JsonObject payments = new JsonObject(message.getPayload());
        orderService.updateStatus(payments.getString("orderId"), payments.getString("status"));

        return message.ack();
    }

}
----

次に `src/main/resources/application.properties` ファイルの `# TODO: Add for messaging configuration` マーカーに設定を追加してみましょう :

[source,none,role="copypaste"]
----
# Incoming payment topic messages
mp.messaging.incoming.payments.connector=smallrye-kafka
mp.messaging.incoming.payments.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.payments.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.payments.bootstrap.servers=my-cluster-kafka-bootstrap:9092
mp.messaging.incoming.payments.group.id=order-service
mp.messaging.incoming.payments.auto.offset.reset=earliest
mp.messaging.incoming.payments.enable.auto.commit=true

# Enable CORS requests from browsers
quarkus.http.cors=true

# Incoming order topic messages
mp.messaging.incoming.orders.connector=smallrye-kafka
mp.messaging.incoming.orders.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.orders.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.orders.bootstrap.servers=my-cluster-kafka-bootstrap:9092
mp.messaging.incoming.orders.group.id=order-service
mp.messaging.incoming.orders.auto.offset.reset=earliest
mp.messaging.incoming.orders.enable.auto.commit=true
----

次のコマンドを使用して注文サービスを再パッケージ化し、CodeReady Workspaces Terminal を介してデプロイするために maven プラグインを使用します。:

[source,sh,role="copypaste"]
----
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/order-service && \
oc label dc/order app.kubernetes.io/part-of=order --overwrite &&  \
oc annotate dc/order app.openshift.io/connects-to=my-cluster,order-database --overwrite
----

すべての再構築と再配置が完了するのを待てば、青い丸がすべて完成します！

image::coolstore-ui_event-topology.png[coolstore-ui, 700]

Coolstore の GUI テストで `Kafka` メッセージングを使って、すべてのサービスが正常に動作するかどうかを確認してみましょう。

=== 5. エンドツーエンドの機能テスト

お買い物に行こう。 http://coolstore-ui-{{ USER_ID }}-cloudnativeapps.{{ ROUTE_SUBDOMAIN }}[Red Hat Cool Store^] にアクセスします。

以下のショッピングシナリオでは、ショッピングカートにいくつかのクールなアイテムを追加します。:

[arabic]
. *Add to Cart* をクリックして、 _Quarkus T-shirt_ をカートに追加してください。トップメニューの下に `Success! Added!` というメッセージが表示されます。

image::add-to-cart.png[serverless, 1000]

[arabic, start=2]
. *Cart* タブに移動し、 *Checkout* ボタンをクリックします。クレジットカード情報を入力します。カード情報は16桁で、数字の `4` で始まる必要があります。例えば、 `4123987754646678` のようになります。

[NOTE]
====
当社の偽クレジットカード処理業者は、`4`で始まるクレジットカード番号を探します。`4 で始まらないクレジットカード番号は `FAILED` 処理になります。これは、私たちのコードのロジックをチェックする良い方法です。
====

image::checkout.png[serverless, 1000]

[arabic, start=3]
. クレジットカード情報を入力して商品をお支払いください :

image::input-cc-info.png[serverless, 1000]

[arabic, start=4]
. *Orders* タブの _Payment Status_ を確認してください。 `Processing` になっているはずです。

image::payment-processing.png[serverless, 1000]

[arabic, start=5]
. しばらくしてから、 *AOrders* ページをリロードして、支払いステータスが `COMPLETED` または `FAILED` に変更されたことを確認してください。

[NOTE]
====
ステータスが Processing のままの場合は、注文サービスが受信した Kafka メッセージを処理して MongoDB に保存しています。あと数回ページをリロードしてください。
====

image::payment-completedorfailed.png[serverless, 1000]

=== 概要

このシナリオでは、_Apache Kafka_を使用して、ショッピングカートサービスから注文サービス、決済サービスまでのデータストリームを扱う _Event-Driven/Reactive_ Cloud Native アプリを開発しました。また、アプリを Kafka と統合するために、Quarkus とその _Kafka extension_ を使用しました。Red Hat が完全にサポートしている Kafka ソリューションである _AMQ Streams_ を使用すると、OpenShift の開発者カタログを介して Apache Kafka クラスタを非常に簡単に作成することができます。

現在では、リアクティブシステムを実装するためのメッセージ駆動型のマイクロサービスがあり、すべてのコンポーネントが非同期のメッセージパッシングを使用して相互作用するため、信頼性、拡張性、市場投入までの時間が短縮されています。最も重要なことは、Quarkus は、イベント駆動型のマイクロサービスやリアクティブシステムの実装に完璧に適しているということです。*Congratulations!*
